{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"h4FrD3jz2LOW"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Reshape, Flatten, Lambda"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SLj3ouQg2zBa"},"outputs":[],"source":["df = pd.read_csv('final.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yejFT_5tlEC6"},"outputs":[],"source":["df = df.sample(frac=1).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"jniIPx1m3mCL","outputId":"26ac0fe6-508b-4908-bf9e-0744e5b5b573"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>ID</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>You may want to drop the col1 column.</td>\n","      <td>4</td>\n","      <td>df.drop(columns = 'col1',inplace = True)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The column should be dropped.</td>\n","      <td>4</td>\n","      <td>df.drop(columns = 'col1',inplace = True)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The col 1 column must be dropped.</td>\n","      <td>4</td>\n","      <td>df.drop(columns = 'col1',inplace = True)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The dataframe was sorted by col1, col2 and col3.</td>\n","      <td>3</td>\n","      <td>df.sort_values(by=[‘col1’, ‘col2’, ‘col3’], in...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Send me a list of col 1 and col 2.</td>\n","      <td>5</td>\n","      <td>new_df=df.loc[:, ['col1','col2']]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           Sentence  ID  \\\n","0             You may want to drop the col1 column.   4   \n","1                     The column should be dropped.   4   \n","2                 The col 1 column must be dropped.   4   \n","3  The dataframe was sorted by col1, col2 and col3.   3   \n","4                Send me a list of col 1 and col 2.   5   \n","\n","                                              Target  \n","0           df.drop(columns = 'col1',inplace = True)  \n","1           df.drop(columns = 'col1',inplace = True)  \n","2           df.drop(columns = 'col1',inplace = True)  \n","3  df.sort_values(by=[‘col1’, ‘col2’, ‘col3’], in...  \n","4                  new_df=df.loc[:, ['col1','col2']]  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rFR4gYCr3nuS","outputId":"856f7e0a-0e43-4f0b-9633-cd28451d1692"},"outputs":[{"data":{"text/plain":["(984, 3)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esdi6PPly08X","outputId":"01f37481-5356-4645-c6ac-7273db1a4fb7"},"outputs":[{"data":{"text/plain":["0               df.drop(columns = 'col1',inplace = True)\n","1               df.drop(columns = 'col1',inplace = True)\n","2               df.drop(columns = 'col1',inplace = True)\n","3      df.sort_values(by=[‘col1’, ‘col2’, ‘col3’], in...\n","4                      new_df=df.loc[:, ['col1','col2']]\n","                             ...                        \n","979                    new_df=df.loc[:, ['col1','col2']]\n","980                            df['col1'].value_counts()\n","981                            df['col1'].value_counts()\n","982                            df['col1'].value_counts()\n","983            df.sort_values(by=[‘col1’], inplace=True)\n","Name: Target, Length: 984, dtype: object"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df['Target']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yA_0ihY5336g"},"outputs":[],"source":["# Initialize the tokenizer with filters set to none so it doesn't remove any characters\n","tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n","\n","# Fit the tokenizer on the input and target sequences\n","tokenizer.fit_on_texts(df['Patterns'])\n","tokenizer.fit_on_texts(df['Target'])\n","\n","# Convert the input and target sequences to numerical sequences\n","input_sequences = tokenizer.texts_to_sequences(df['Patterns'])\n","target_sequences = tokenizer.texts_to_sequences(df['Target'])\n","\n","# Determine the length of the longest input sequence and target sequence\n","max_input_length = max(len(seq) for seq in input_sequences)\n","max_target_length = max(len(seq) for seq in target_sequences)\n","\n","# Pad the input and target sequences to the maximum length\n","padded_input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, \n","                                                                       maxlen=max_input_length, \n","                                                                       padding='post')\n","padded_target_sequences = tf.keras.preprocessing.sequence.pad_sequences(target_sequences, \n","                                                                        maxlen=max_target_length, \n","                                                                        padding='post')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7j2Ia-4Yl__j"},"outputs":[],"source":["import pickle\n","\n","# Save the tokenizer\n","with open('tokenizer.pkl', 'wb') as f:\n","    pickle.dump(tokenizer, f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-lcssJ0q3-Sd"},"outputs":[],"source":["# Set the percentage of the data to use for validation\n","test_percent = 0.2\n","\n","# Determine the number of samples to use for validation\n","num_test_samples = int(len(df) * test_percent)\n","\n","# Split the data into training and validation sets\n","train_input = padded_input_sequences[:-num_test_samples]\n","train_target = padded_target_sequences[:-num_test_samples]\n","test_input = padded_input_sequences[-num_test_samples:]\n","test_target = padded_target_sequences[-num_test_samples:]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6s_2uONx9C6O"},"outputs":[],"source":["# Define the input shape\n","encoder_inputs = Input(shape=(max_input_length,))\n","decoder_inputs = Input(shape=(max_target_length-1,))\n","\n","# Define the embedding layer\n","embedding_layer = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=256)\n","\n","# Apply the embedding layer to the inputs\n","encoder_inputs_embedded = embedding_layer(encoder_inputs)\n","decoder_inputs_embedded = embedding_layer(decoder_inputs)\n","\n","# Define the encoder LSTM\n","encoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs_embedded)\n","\n","# Define the decoder LSTM\n","decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs_embedded, initial_state=[state_h, state_c])\n","\n","# Define the output layer\n","output_layer = Dense(len(tokenizer.word_index)+1, activation='softmax')\n","outputs = output_layer(decoder_outputs)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYdXvdur3_zT"},"outputs":[],"source":["# Define the model\n","input_sequence_length = max_input_length\n","output_sequence_length = max_target_length - 1\n","input_vocab_size = len(tokenizer.word_index) + 1\n","output_vocab_size = len(tokenizer.word_index) + 1\n","hidden_size = 256\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5xRrTyd9jRE","outputId":"18f8ac16-c565-4caa-b3f1-1dad76d1bc20"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n"]},{"name":"stderr","output_type":"stream","text":["/Users/rithvik17/opt/anaconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 5s 136ms/step - loss: 8.1065 - accuracy: 0.1434\n","Epoch 2/30\n","7/7 [==============================] - 1s 137ms/step - loss: 2.6979 - accuracy: 0.6675\n","Epoch 3/30\n","7/7 [==============================] - 1s 133ms/step - loss: 2.0354 - accuracy: 0.6669\n","Epoch 4/30\n","7/7 [==============================] - 1s 134ms/step - loss: 1.8472 - accuracy: 0.6685\n","Epoch 5/30\n","7/7 [==============================] - 1s 132ms/step - loss: 1.5704 - accuracy: 0.7167\n","Epoch 6/30\n","7/7 [==============================] - 1s 135ms/step - loss: 1.2337 - accuracy: 0.7751\n","Epoch 7/30\n","7/7 [==============================] - 1s 134ms/step - loss: 0.9009 - accuracy: 0.8623\n","Epoch 8/30\n","7/7 [==============================] - 1s 134ms/step - loss: 0.8076 - accuracy: 0.8560\n","Epoch 9/30\n","7/7 [==============================] - 1s 137ms/step - loss: 0.6121 - accuracy: 0.9210\n","Epoch 10/30\n","7/7 [==============================] - 1s 134ms/step - loss: 0.9437 - accuracy: 0.8445\n","Epoch 11/30\n","7/7 [==============================] - 1s 135ms/step - loss: 1.1958 - accuracy: 0.7728\n","Epoch 12/30\n","7/7 [==============================] - 1s 135ms/step - loss: 1.0946 - accuracy: 0.7795\n","Epoch 13/30\n","7/7 [==============================] - 1s 135ms/step - loss: 0.9888 - accuracy: 0.8049\n","Epoch 14/30\n","7/7 [==============================] - 1s 134ms/step - loss: 0.9002 - accuracy: 0.8956\n","Epoch 15/30\n","7/7 [==============================] - 1s 135ms/step - loss: 0.8186 - accuracy: 0.9261\n","Epoch 16/30\n","7/7 [==============================] - 1s 153ms/step - loss: 0.7331 - accuracy: 0.9378\n","Epoch 17/30\n","7/7 [==============================] - 1s 163ms/step - loss: 0.6487 - accuracy: 0.9375\n","Epoch 18/30\n","7/7 [==============================] - 1s 138ms/step - loss: 0.5473 - accuracy: 0.9378\n","Epoch 19/30\n","7/7 [==============================] - 1s 138ms/step - loss: 0.4376 - accuracy: 0.9375\n","Epoch 20/30\n","7/7 [==============================] - 1s 139ms/step - loss: 0.3724 - accuracy: 0.9375\n","Epoch 21/30\n","7/7 [==============================] - 1s 149ms/step - loss: 0.3618 - accuracy: 0.9381\n","Epoch 22/30\n","7/7 [==============================] - 1s 168ms/step - loss: 0.3426 - accuracy: 0.9426\n","Epoch 23/30\n","7/7 [==============================] - 1s 139ms/step - loss: 0.3360 - accuracy: 0.9457\n","Epoch 24/30\n","7/7 [==============================] - 1s 161ms/step - loss: 0.3298 - accuracy: 0.9454\n","Epoch 25/30\n","7/7 [==============================] - 1s 138ms/step - loss: 0.3252 - accuracy: 0.9448\n","Epoch 26/30\n","7/7 [==============================] - 1s 136ms/step - loss: 0.3212 - accuracy: 0.9445\n","Epoch 27/30\n","7/7 [==============================] - 1s 156ms/step - loss: 0.3175 - accuracy: 0.9461\n","Epoch 28/30\n","7/7 [==============================] - 1s 174ms/step - loss: 0.3142 - accuracy: 0.9464\n","Epoch 29/30\n","7/7 [==============================] - 1s 157ms/step - loss: 0.3114 - accuracy: 0.9464\n","Epoch 30/30\n","7/7 [==============================] - 1s 139ms/step - loss: 0.3085 - accuracy: 0.9477\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fb9787b59a0>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["from keras.optimizers import Adam\n","# Define the model\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","#  Compile the model\n","learning_rate = 0.001\n","optimizer = Adam(lr=learning_rate)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","#  Train the model\n","model.fit([train_input, train_target[:, :-1]], train_target[:, 1:], batch_size=128, epochs=30, validation_split=0.0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRjoUhxjCD_S","outputId":"3a69bdc9-4845-4227-dcda-73a059656988"},"outputs":[{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 1s 27ms/step - loss: 0.3423 - accuracy: 0.9452\n","Test loss: 0.3422703146934509\n","Test accuracy: 0.9451530575752258\n"]}],"source":["# Test the model\n","test_loss, test_acc = model.evaluate([test_input, test_target[:, :-1]], test_target[:, 1:])\n","print('Test loss:', test_loss)\n","print('Test accuracy:', test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fIIF6uir_nHY","outputId":"e0b324f7-72e8-42fb-838f-aca6511aeab9"},"outputs":[{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 1s 39ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.92      1.00      0.96       506\n","           3       1.00      1.00      1.00        86\n","          16       1.00      1.00      1.00        43\n","          17       1.00      0.00      0.00        43\n","          19       1.00      1.00      1.00        41\n","          21       1.00      1.00      1.00        43\n","          54       1.00      1.00      1.00         7\n","          55       1.00      1.00      1.00         7\n","          56       1.00      1.00      1.00         8\n","\n","    accuracy                           0.95       784\n","   macro avg       0.99      0.89      0.88       784\n","weighted avg       0.95      0.95      0.92       784\n","\n"]}],"source":["test_predictions = model.predict([test_input, test_target[:, :-1]])\n","\n","test_predictions = np.argmax(test_predictions, axis=-1)\n","\n","true_targets = test_target[:, 1:].flatten()\n","predicted_targets = test_predictions.flatten()\n","\n","from sklearn.metrics import classification_report\n","report = classification_report(true_targets, predicted_targets, zero_division=1)\n","print(report)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TgDcjb6mzzlh"},"outputs":[],"source":["model.save('seq2seq_model.h5')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}